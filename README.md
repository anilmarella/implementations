# Deep Neural network implementation

This notebook has end to end deep neural network implementation from scratch.

1. This implementation uses only sigmoid activation
2. Optimization techniques implemented are classic gradient descent, gradient descent with momentum, RMSProp and  Adam optimization. All of these are mini-batched by default
3. The deep neural network is implemented only with L2 - Regularization

**Note:** The notebook has many similarities to the programming assignments from [Coursera Deep learning courses](https://www.coursera.org/specializations/deep-learning "Deep learning Specialization") because that is where I learned it.
